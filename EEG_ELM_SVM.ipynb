{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment2_p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this Assignment I use SVM and ELM algorithm to train this EEG Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='black' size=3 face=\"Times New Roman\"> First I use fixed-elm algorithm to train EEG , in order to see In order to compare the influence of the number of neurons on the network,  I set up a for loop of 100, 200, 500, 800, 1000 neurons, recording accuracy.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangxiang/Library/Python/3.6/lib/python/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/wangxiang/Library/Python/3.6/lib/python/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/wangxiang/Library/Python/3.6/lib/python/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/wangxiang/Library/Python/3.6/lib/python/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/wangxiang/Library/Python/3.6/lib/python/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/wangxiang/Library/Python/3.6/lib/python/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/wangxiang/Code/EEG_Practice/load_data.py:10: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/wangxiang/Code/EEG_Practice/load_data.py:11: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangxiang/Library/Python/3.6/lib/python/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/wangxiang/Library/Python/3.6/lib/python/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/wangxiang/Library/Python/3.6/lib/python/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/wangxiang/Library/Python/3.6/lib/python/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/wangxiang/Library/Python/3.6/lib/python/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/wangxiang/Library/Python/3.6/lib/python/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start downloading dataset...\n",
      "WARNING:tensorflow:From /Users/wangxiang/Code/EEG_Practice/load_data.py:16: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "Successfully downloaded train 209530726 bytes.\n",
      "Start downloading dataset...\n",
      "Successfully downloaded test 144273978 bytes.\n"
     ]
    }
   ],
   "source": [
    "import load_data\n",
    "\n",
    "# return DataSet class\n",
    "data = load_data.read_data_sets(one_hot=False)\n",
    "# get sample number\n",
    "n_samples = data.train.num_examples\n",
    "# get train data and labels by batch size\n",
    "train_x, train_label = data.train.next_batch(n_samples)\n",
    "\n",
    "# get test data\n",
    "test_x = data.test.data\n",
    "\n",
    "# get test labels\n",
    "test_labels = data.test.labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of  100 neurons Testing Accuracy is  0.4585225708780622\n",
      "The number of  200 neurons Testing Accuracy is  0.4837255711533168\n",
      "The number of  500 neurons Testing Accuracy is  0.5622247453894853\n",
      "The number of  800 neurons Testing Accuracy is  0.5580443159922929\n",
      "The number of  1000 neurons Testing Accuracy is  0.5932252958987063\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import elm\n",
    "\n",
    "import load_data\n",
    "\n",
    "number_neruon= [100,200,500,800,1000]\n",
    "for i in number_neruon:\n",
    "    elmc = elm.ELMClassifier(n_hidden=i,activation_func='tanh')\n",
    "    data = load_data.read_data_sets(one_hot=True)\n",
    "\n",
    "#     elmc.fit(data.train.data,data.train.labels)\n",
    "#     Accuracy = elmc.score(data.test.data,data.test.labels)\n",
    "    elmc.fit(train_x,train_label)\n",
    "    Accuracy = elmc.score(test_x,test_labels)\n",
    "\n",
    "    print(\"The number of \",i ,\"neurons\",\"Testing Accuracy is \",Accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second , beacuse the performance of ELM is not good, so I use  SVM Algorithm, And I use SVM with different kernel to see performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='black' size=3 face=\"黑体\">First I use 'linear' kernel to test this dataset </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier.fit(train_x,train_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9097  7792  1549]\n",
      " [ 3720 14622  1398]\n",
      " [ 2302  1133 16515]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.49      0.54     18438\n",
      "           1       0.62      0.74      0.68     19740\n",
      "           2       0.85      0.83      0.84     19950\n",
      "\n",
      "    accuracy                           0.69     58128\n",
      "   macro avg       0.69      0.69      0.69     58128\n",
      "weighted avg       0.69      0.69      0.69     58128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(test_labels,y_pred))\n",
    "print(classification_report(test_labels,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='black' size=3 face=\"Times New Roman\">Using SVM with 'linear' kernel performace is : 69% \n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='black' size=3 face=\"Times New Roman\">Second  I use another kernel 'poly' to test this dataset </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='poly',degree=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import load_data\n",
    "\n",
    "# # return DataSet class\n",
    "# data = load_data.read_data_sets(one_hot=False)\n",
    "\n",
    "# # get train data and labels by batch size\n",
    "# train_x, train_label = data.train.next_batch(n_samples)\n",
    "\n",
    "# # get test data\n",
    "# test_x = data.test.data\n",
    "\n",
    "# # get test labels\n",
    "# test_labels = data.test.labels\n",
    "\n",
    "# # get sample number\n",
    "# n_samples = data.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=8, gamma='auto_deprecated',\n",
       "    kernel='poly', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier.fit(train_x,train_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8690  8269  1479]\n",
      " [ 2495 15894  1351]\n",
      " [ 2458   816 16676]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.47      0.54     18438\n",
      "           1       0.64      0.81      0.71     19740\n",
      "           2       0.85      0.84      0.85     19950\n",
      "\n",
      "    accuracy                           0.71     58128\n",
      "   macro avg       0.71      0.70      0.70     58128\n",
      "weighted avg       0.71      0.71      0.70     58128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(test_labels,y_pred))\n",
    "print(classification_report(test_labels,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='black' size=3 face=\"Times New Roman\">Using SVM with 'poly' kernel performace is : 70% </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='black' size=3 face=\"黑体\"></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='black' size=3 face=\"Times New Roman\">Third i use another kernel 'rbf' to test this dataset </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='rbf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier.fit(train_x,train_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10925  5714  1799]\n",
      " [ 1474 17657   609]\n",
      " [  685  1060 18205]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.59      0.69     18438\n",
      "           1       0.72      0.89      0.80     19740\n",
      "           2       0.88      0.91      0.90     19950\n",
      "\n",
      "    accuracy                           0.80     58128\n",
      "   macro avg       0.81      0.80      0.80     58128\n",
      "weighted avg       0.81      0.80      0.80     58128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(test_labels,y_pred))\n",
    "print(classification_report(test_labels,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='black' size=3 face=\"Times New Roman\">Using SVM with 'rbf' kernel performace is : 80% \n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='black' size=3 face=\"Times New Roman\">In this assigment , I use two algorithm to test this EEG , and especially,in terms of SVM I use several kernel to compare this performace </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='black' size=3 face=\"Times New Roman\">For Fixed-ELM, the performace is just 59% for 1K neruons,so we can see that is not good and it is not my expection. Then, I use SVM ,for SVM I use several kernels : 'linear' 'poly' 'rbf' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='black' size=3 face=\"Times New Roman\">so compare those performace,I found that Using SVM with 'rbf' kernel the performace is best,it is 80% ,which is much better than ELM and other algorithms  </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
